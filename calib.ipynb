{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibrating camera .... Please wait...\n",
      "Camera matrix is \n",
      " [[901.44184954   0.         627.54487483]\n",
      " [  0.         904.66841265 379.96880038]\n",
      " [  0.           0.           1.        ]] \n",
      " And is stored in calibration.yaml file along with distortion coefficients : \n",
      " [[ 2.90064989e-01 -1.34252056e+00 -1.08080778e-03 -1.91921295e-03\n",
      "   2.35356968e+00]]\n",
      "Total error: 0.05515785854432075\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import glob\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "CHESSBOARD_CORNER_NUM_X = 10\n",
    "CHESSBOARD_CORNER_NUM_Y = 7\n",
    "IMAGE_SRC = \"cam1_images\"\n",
    "CAMERA_PARAMETERS_OUTPUT_FILE = \"cam1.yaml\"\n",
    "\n",
    "root = Path.cwd()\n",
    "\n",
    "# Set path to the images\n",
    "calib_imgs_path = root.joinpath(IMAGE_SRC)\n",
    "\n",
    "# termination criteria\n",
    "criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(8,5,0)\n",
    "objp = np.zeros((CHESSBOARD_CORNER_NUM_X*CHESSBOARD_CORNER_NUM_Y, 3), np.float32)\n",
    "objp[:, :2] = np.mgrid[0:CHESSBOARD_CORNER_NUM_X, 0:CHESSBOARD_CORNER_NUM_Y].T.reshape(-1, 2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = []  # 3d point in real world space\n",
    "imgpoints = []  # 2d points in image plane.\n",
    "\n",
    "images = calib_imgs_path.glob('*.jpg')\n",
    "for fname in images:\n",
    "    img = cv.imread(str(root.joinpath(fname)))\n",
    "    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    # Find the chess board corners\n",
    "    ret, corners = cv.findChessboardCorners(gray, (CHESSBOARD_CORNER_NUM_X, CHESSBOARD_CORNER_NUM_Y), None)\n",
    "    # If found, add object points, image points (after refining them)\n",
    "    if ret:\n",
    "        objpoints.append(objp)\n",
    "        corners2 = cv.cornerSubPix(gray, corners, (11, 11), (-1, -1), criteria)\n",
    "        imgpoints.append(corners)\n",
    "        # Draw and display the corners\n",
    "        cv.drawChessboardCorners(img, (CHESSBOARD_CORNER_NUM_X, CHESSBOARD_CORNER_NUM_Y), corners2, ret)\n",
    "        cv.imshow('img', img)\n",
    "        cv.waitKey(500)\n",
    "    else:\n",
    "        print('Failed to find a chessboard in {}'.format(fname))\n",
    "\n",
    "cv.destroyAllWindows()\n",
    "\n",
    "print(\"Calibrating camera .... Please wait...\")\n",
    "ret, mtx, dist, rvecs, tvecs = cv.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "\n",
    "print(\"Camera matrix is \\n\", mtx, \"\\n And is stored in calibration.yaml file along with distortion coefficients : \\n\", dist)\n",
    "\n",
    "mean_error = 0\n",
    "for i in range(len(objpoints)):\n",
    "    imgpoints2, _ = cv.projectPoints(objpoints[i], rvecs[i], tvecs[i], mtx, dist)\n",
    "    error = cv.norm(imgpoints[i], imgpoints2, cv.NORM_L2) / len(imgpoints2)\n",
    "    mean_error += error\n",
    "\n",
    "print(\"Total error: {}\".format(mean_error / len(objpoints)))\n",
    "\n",
    "data = {'camera_matrix': np.asarray(mtx).tolist(), 'dist_coeff': np.asarray(dist).tolist()}\n",
    "with open(CAMERA_PARAMETERS_OUTPUT_FILE, \"w\") as f:\n",
    "    yaml.dump(data, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USING CHESSBOARD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibrating camera .... Please wait...\n",
      "Camera matrix is \n",
      " [[901.44204508   0.         627.54480678]\n",
      " [  0.         904.66861291 379.96878104]\n",
      " [  0.           0.           1.        ]] \n",
      " And is stored in calibration.yaml file along with distortion coefficients : \n",
      " [[ 2.90064547e-01 -1.34251639e+00 -1.08082547e-03 -1.91922978e-03\n",
      "   2.35356175e+00]]\n",
      "Total error: 0.055157898976098005\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import glob\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "CHESSBOARD_CORNER_NUM_X = 10\n",
    "CHESSBOARD_CORNER_NUM_Y = 7\n",
    "IMAGE_SRC = \"cam1_images\"\n",
    "CAMERA_PARAMETERS_OUTPUT_FILE = \"cam1.yaml\"\n",
    "\n",
    "# Thay vì sử dụng __file__, bạn sử dụng thư mục hiện tại\n",
    "root = Path.cwd()\n",
    "\n",
    "# Set path to the images\n",
    "calib_imgs_path = root.joinpath(IMAGE_SRC)\n",
    "\n",
    "# termination criteria\n",
    "criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "square_size = 24  # Giả sử độ dài cạnh của mỗi ô vuông là 25mm\n",
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(9,6,0) và nhân với kích thước ô vuông thực tế\n",
    "objp = np.zeros((CHESSBOARD_CORNER_NUM_X*CHESSBOARD_CORNER_NUM_Y, 3), np.float32)\n",
    "objp[:, :2] = np.mgrid[0:CHESSBOARD_CORNER_NUM_X, 0:CHESSBOARD_CORNER_NUM_Y].T.reshape(-1, 2) * square_size\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = []  # 3d point in real world space\n",
    "imgpoints = []  # 2d points in image plane.\n",
    "\n",
    "images = calib_imgs_path.glob('*.jpg')\n",
    "for fname in images:\n",
    "    img = cv.imread(str(root.joinpath(fname)))\n",
    "    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    # Find the chess board corners\n",
    "    ret, corners = cv.findChessboardCorners(gray, (CHESSBOARD_CORNER_NUM_X, CHESSBOARD_CORNER_NUM_Y), None)\n",
    "    # If found, add object points, image points (after refining them)\n",
    "    if ret:\n",
    "        objpoints.append(objp)\n",
    "        corners2 = cv.cornerSubPix(gray, corners, (11, 11), (-1, -1), criteria)\n",
    "        imgpoints.append(corners)\n",
    "        # Draw and display the corners\n",
    "        cv.drawChessboardCorners(img, (CHESSBOARD_CORNER_NUM_X, CHESSBOARD_CORNER_NUM_Y), corners2, ret)\n",
    "        cv.imshow('img', img)\n",
    "        cv.waitKey(500)\n",
    "    else:\n",
    "        print('Failed to find a chessboard in {}'.format(fname))\n",
    "\n",
    "cv.destroyAllWindows()\n",
    "\n",
    "print(\"Calibrating camera .... Please wait...\")\n",
    "ret, mtx, dist, rvecs, tvecs = cv.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "\n",
    "print(\"Camera matrix is \\n\", mtx, \"\\n And is stored in calibration.yaml file along with distortion coefficients : \\n\", dist)\n",
    "\n",
    "mean_error = 0\n",
    "for i in range(len(objpoints)):\n",
    "    imgpoints2, _ = cv.projectPoints(objpoints[i], rvecs[i], tvecs[i], mtx, dist)\n",
    "    error = cv.norm(imgpoints[i], imgpoints2, cv.NORM_L2) / len(imgpoints2)\n",
    "    mean_error += error\n",
    "\n",
    "print(\"Total error: {}\".format(mean_error / len(objpoints)))\n",
    "\n",
    "data = {'camera_matrix': np.asarray(mtx).tolist(), 'dist_coeff': np.asarray(dist).tolist()}\n",
    "with open(CAMERA_PARAMETERS_OUTPUT_FILE, \"w\") as f:\n",
    "    yaml.dump(data, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This code assumes that images used for calibration are of the same arUco marker board provided with code\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import cv2\n",
    "from cv2 import aruco\n",
    "import yaml\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# root directory of repo for relative path specification.\n",
    "root = Path.cwd()\n",
    "\n",
    "# Set this flsg True for calibrating camera and False for validating results real time\n",
    "calibrate_camera = True\n",
    "\n",
    "# Set path to the images\n",
    "calib_imgs_path = root.joinpath(\"C:\\\\Users\\\\phamnhat\\\\Desktop\\\\computer vision\\\\cam2_images\")\n",
    "\n",
    "# For validating results, show aruco board to camera.\n",
    "aruco_dict = aruco.getPredefinedDictionary( aruco.DICT_6X6_1000 )\n",
    "\n",
    "#Provide length of the marker's side\n",
    "markerLength = 3.75  # Here, measurement unit is centimetre.\n",
    "\n",
    "# Provide separation between markers\n",
    "markerSeparation = 0.5   # Here, measurement unit is centimetre.\n",
    "\n",
    "# create arUco board\n",
    "board = aruco.GridBoard((4, 5), markerLength, markerSeparation, aruco_dict)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ...0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 Calibration images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:00<00:00, 36.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19] unique markers\n",
      "Calibrating camera .... Please wait...\n",
      "Camera matrix is \n",
      " [[1.12827978e+03 0.00000000e+00 6.57164745e+02]\n",
      " [0.00000000e+00 1.13306387e+03 3.36362350e+02]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00]] \n",
      " And is stored in calibration.yaml file along with distortion coefficients : \n",
      " [[ 0.07304058 -0.79128477 -0.00191665  0.00451977  0.7964234 ]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "arucoParams = aruco.DetectorParameters()\n",
    "\n",
    "if calibrate_camera == True:\n",
    "    img_list = []\n",
    "    calib_fnms = calib_imgs_path.glob('*.jpg')\n",
    "    print('Using ...', end='')\n",
    "    for idx, fn in enumerate(calib_fnms):\n",
    "        print(idx, '', end='')\n",
    "        img = cv2.imread( str(root.joinpath(fn) ))\n",
    "        img_list.append( img )\n",
    "        h, w, c = img.shape\n",
    "    print('Calibration images')\n",
    "\n",
    "    counter, corners_list, id_list = [], [], []\n",
    "    first = True\n",
    "    for im in tqdm(img_list):\n",
    "        img_gray = cv2.cvtColor(im,cv2.COLOR_RGB2GRAY)\n",
    "        corners, ids, rejectedImgPoints = aruco.detectMarkers(img_gray, aruco_dict, parameters=arucoParams)\n",
    "        if first == True:\n",
    "            corners_list = corners\n",
    "            id_list = ids\n",
    "            first = False\n",
    "        else:\n",
    "            corners_list = np.vstack((corners_list, corners))\n",
    "            id_list = np.vstack((id_list,ids))\n",
    "        counter.append(len(ids))\n",
    "    print('Found {} unique markers'.format(np.unique(ids)))\n",
    "\n",
    "    counter = np.array(counter)\n",
    "    print (\"Calibrating camera .... Please wait...\")\n",
    "    #mat = np.zeros((3,3), float)\n",
    "    ret, mtx, dist, rvecs, tvecs = aruco.calibrateCameraAruco(corners_list, id_list, counter, board, img_gray.shape, None, None )\n",
    "\n",
    "    print(\"Camera matrix is \\n\", mtx, \"\\n And is stored in calibration.yaml file along with distortion coefficients : \\n\", dist)\n",
    "    data = {'camera_matrix': np.asarray(mtx).tolist(), 'dist_coeff': np.asarray(dist).tolist()}\n",
    "    with open(\"calibration.yaml\", \"w\") as f:\n",
    "        yaml.dump(data, f)\n",
    "\n",
    "else:\n",
    "    camera = cv2.VideoCapture(0)\n",
    "    ret, img = camera.read()\n",
    "\n",
    "    with open('calibration.yaml') as f:\n",
    "        loadeddict = yaml.load(f)\n",
    "    mtx = loadeddict.get('camera_matrix')\n",
    "    dist = loadeddict.get('dist_coeff')\n",
    "    mtx = np.array(mtx)\n",
    "    dist = np.array(dist)\n",
    "\n",
    "    ret, img = camera.read()\n",
    "    img_gray = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
    "    h,  w = img_gray.shape[:2]\n",
    "    newcameramtx, roi=cv2.getOptimalNewCameraMatrix(mtx,dist,(w,h),1,(w,h))\n",
    "\n",
    "    pose_r, pose_t = [], []\n",
    "    while True:\n",
    "        ret, img = camera.read()\n",
    "        img_aruco = img\n",
    "        im_gray = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
    "        h,  w = im_gray.shape[:2]\n",
    "        dst = cv2.undistort(im_gray, mtx, dist, None, newcameramtx)\n",
    "        corners, ids, rejectedImgPoints = aruco.detectMarkers(dst, aruco_dict, parameters=arucoParams)\n",
    "        #cv2.imshow(\"original\", img_gray)\n",
    "        if corners == None:\n",
    "            print (\"pass\")\n",
    "        else:\n",
    "\n",
    "            ret, rvec, tvec = aruco.estimatePoseBoard(corners, ids, board, newcameramtx, dist) # For a board\n",
    "            print (\"Rotation \", rvec, \"Translation\", tvec)\n",
    "            if ret != 0:\n",
    "                img_aruco = aruco.drawDetectedMarkers(img, corners, ids, (0,255,0))\n",
    "                img_aruco = aruco.drawAxis(img_aruco, newcameramtx, dist, rvec, tvec, 10)    # axis length 100 can be changed according to your requirement\n",
    "\n",
    "            if cv2.waitKey(0) & 0xFF == ord('q'):\n",
    "                break;\n",
    "        cv2.imshow(\"World co-ordinate frame axes\", img_aruco)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
